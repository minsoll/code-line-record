Crawler 기어다니면서 데이터를 모은다.<br>
pip install requests <br>
#pip라는 도구가 requests 설치해줌<br>


## 파이썬 함수

조립 기계(갈색 블록,초록색 블록)

construct_machine( brown block, grenn block)

## 파이썬모듈

requests<br>
get 함수 : return 응답값<br>
`import requests `<br>
`url = "http://www.daum.net"` <br>
`response = requests.get(url)` <br>

` print(response.text) `<br>

[참조](https://docs.python-requests.org/en/master/api/#requests.Response)


200성공의미

## Beautiful Soup <br>
BeautifulSoup (데이터, 파써) <br>


r=read <br>
w=write <br>
a=append <br>

## 실시간 검색어 가져오기<br>

```from bs4 import BeautifulSoup


import requests


from datetime import datetime


headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'} <br>
#로봇아님을 명시


url = "https://datalab.naver.com/keyword/realtimeList.naver?age=20s"


response = requests.get(url,headers=headers)


soup = BeautifulSoup(response.text, 'html.parser')


rank = 1


results = soup.findAll('span','item_title')

print(response.text)


search_rank_file = open("rankresult.txt","a")


print(datetime.today().strftime("%Y년 %m월 %d일의 실시간 검색어 순위입니다.\n"))


for result in results:


    search_rank_file.write(str(rank)+"위:"+result.get_text()+"\n")
    
    
    print(rank,"위 : ",result.get_text(),"\n")
    
    
    rank += 1 <br> 
 ```
    
    
    

## 날씨정보 가져오기 
 * API란? <br>
 클라이언트와 서버사이 연결
 
 f string {} 안에 넣어서 사용
 
 b9cb30896da8029410064a378b6b0f01
    
    
